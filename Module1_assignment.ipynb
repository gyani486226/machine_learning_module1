{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9b90411-a10c-4514-a72d-e572c2a8196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. What is parameter ?\n",
    "#  The values which are passed on any function to perform task is known as parameter\n",
    "#  In terms of machine learning, a parameter refers to the variables that the modela learns from the trainig data\n",
    "#  to make predictions. These parameters are adjusted during the training process to minimize the error in the model's predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dcadedb-8f1b-4653-a42b-7531a2b7a183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. What is correlation and  What does negative correlation mean ?\n",
    "#    Correlation :- Correlation gives the realtionship between two variables, this relationship can be positive,\n",
    "#    negatie or zero,\n",
    "#    Positive correlation ;- It means both variables are directly proportional to each other means if one variables \n",
    "#    is increasing other variables is also increasing.\n",
    "#    Zero correlation :- Means no relationship between both variables both are constant.\n",
    "#    Negative correlation :- If one variables increase and other variables decreases called as negative correlation.\n",
    "#    example- Alcohol consumption and age .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62a0babf-b04a-4d7c-8d0f-f6b44586b5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. Define Machine Learning. What are the main components in Machine Learning?\n",
    "#      Learning pattern from the data called as machine learning.\n",
    "#      It focusses on creating algorithms and statistical models to let computers learn and make predictions \n",
    "#      without explicity programmed.\n",
    "#    The main components of Machine Learning include:\n",
    "#     1. Algorithms: The mathematical models and procedures that the system uses to learn from the data.\n",
    "#     2. Data: The foundation of any ML model. It includes the input data used for training and testing the \n",
    "#      model.\n",
    "#     3. Training: The process of feeding the data to make a model slgorithm called as training.\n",
    "#     4. Testing: After evaluation we check our model is correctly working or not\n",
    "#     4. Evaluation: After the completion of training and testing our model is ready\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c054316d-8245-4a3d-9d6f-58c25b72fcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4. How does loss value help in determining whether the model is good or not?\n",
    "#      The loss value, also known as the loss function or cost function, \n",
    "#      A lower loss value indicates that the model's prediction are closer to the actual values, suggesting\n",
    "#       better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bb4952-c81b-4984-a9b1-07bd2c1b21d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6176c524-eed7-4758-b64b-24bb1355fab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5. What are continuous and categorical variables?'\n",
    "#        Continuous variables: These are the variables that can take on an infinite number of values within a given\n",
    "#        range. Exampleas are height, weight, temperature etc.\n",
    "#        Categorical variables: These are variables that represent distinct categories or groups.\n",
    "#        Examples are gender, blood type and marital status etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e22d3c3-b3ea-4fbc-8138-8c41e951130f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e05ce63e-4ae2-4838-b82f-43c7b806d874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
    "#        Data encoding: The process of converting string or categorical data in to numerical data called as \n",
    "#        data encoding\n",
    "#        Types:\n",
    "#        1. Nominal (One hot encoding)\n",
    "#        2. Label and ordinal\n",
    "#        3. Target guided ordinal encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476fae1f-656c-4756-b721-b912f0203fae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c31478eb-6f2a-4127-b984-a6c4cf028d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7. What do you mean by training and testing a dataset?\n",
    "#      Training Dataset: In our dataset we divide the data in 8:2 or7:3 etc means 8 data point out 10 are\n",
    "#      used for training .\n",
    "#      The dataset used to train the model.\n",
    "#      It contains input data along with the corresponding output(labels).\n",
    "#      With the help of trainig data model learns patterns and relationship from the data.\n",
    "#      Testing Dataset : 2 data out of 10 data are used at the end to check the models accuracy called \n",
    "#      as testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977d5a00-867c-4a7b-86e8-29de6a56177f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab68e457-3ed8-4a23-8e14-d5714b2c5bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8.  What is sklearn.preprocessing?\n",
    "#       sklearn.preprocessing is a module in the Scikit-learn library that provides various utilities \n",
    "#       for preprocessing and transforming data before it is used to train machine learning models.\n",
    "#       With the help of this library we do Standardization, Normalization, Data encoding etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88786a0-5709-41f8-bf50-9bb10c7ee69b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74034497-72b3-4f6c-ab7f-61747f837b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9. What is a Test set? \n",
    "#     A test set is a subset of data used to evaluate the performance of a machine learning model after \n",
    "#     it has been trained. It contains the input data that the model has not seen during the training \n",
    "#     phase, along with the corresponding output(labels). \n",
    "#     The purpose of the test set is to provide an unbiased assessment of how well the model generalizes \n",
    "#      to new, unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecbd559-bf22-4fd3-9155-18a9cfa60ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf41b018-e8dc-4c3a-9506-79eeb5e728d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q10. How do we split data for model fitting (training and testing) in Python?\n",
    "#      In our  dataset we divide the data in 8:2 or7:3 etc for trainig and testing the model\n",
    "\n",
    "#Q10.1 How do you approach a Machine Learning problem?\n",
    "#    Following steps are required for machine learning problem are as:-\n",
    "#        1. Read the data\n",
    "#        2. Exploratory data analysis: Perform EDA to understand the data's characteristics, distribution \n",
    "#         and relationships. Ensure that the data is representating of teh problem you are trying to solve\n",
    "#        3. Data preparation: It includes the clean and preprocess the data and handling missing values, \n",
    "#        encoding categorical variables, scaling numerical features.\n",
    "#        4. Separate the X(Independent) and Y(dependent) Variable.\n",
    "#        5. Model training\n",
    "#        6. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f74b13-4030-47f5-ae1e-1e4bf9069c43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "985c6ba7-fb4c-490a-9bc4-9cb6bd7ffe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q11. Why do we have to perform EDA before fitting a model to the data?\n",
    "#     Exploratory data analysis: \n",
    "#     1. Understanding Data: EDA helps us to understand the underlying structure, patterns, and relationships\n",
    "#     in the data. \n",
    "#     2. Indentifying Anomalies: EDA allows you to detect and handle anomalies, such as missing values, \n",
    "#     outliers, and errors in the data.\n",
    "#     3.Feature selection: with the help of EDA, we can identify the most relevant features in the model. This helps in \n",
    "#     reducing dimensionality and improving the model's efficiency and accuracy.\n",
    "#     4.Data Transformation: With the help od this we can easily predict which series of data wants to be scaling.\n",
    "#     5. Visualization Data: with the help of EDA we visualize the data through plots and charts, which are used to reveal\n",
    "#      insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc43f00-6e41-45c8-a756-312ca375a925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93c8ed89-7ecf-46b0-b8f2-0799bd939c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q12 What is correlation?\n",
    "#    Correlation :- Correlation gives the realtionship between two variables, this relationship can be positive,\n",
    "#    negatie or zero,\n",
    "#    Positive correlation ;- It means both variables are directly proportional to each other means if one variables \n",
    "#    is increasing other variables is also increasing.\n",
    "#    Zero correlation :- Means no relationship between both variables both are constant.\n",
    "#    Negative correlation :- If one variables increase and other variables decreases called as negative correlation.\n",
    "#    example- Alcohol consumption and age ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ee441e-8992-44d3-84aa-cd13c11836b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffbad85f-fa2d-43ab-ba54-b6f4cc3d1556",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q13 What does negative correlation mean?\n",
    "#    Negative correlation :- If one variables increase and other variables decreases called as negative correlation.\n",
    "#    example- Alcohol consumption and age ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0472926c-7ade-4b13-8a6d-87c8cffc0b55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a43ca149-7fa0-4d39-97e3-90e84ea0b7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q14 How can you find correlation between variables in Python?\n",
    "#    with the help of .corr() method from the pandas library we find the correlation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc1626f-8d06-4dda-bb23-4b23fc32294c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e51cca3d-49a4-445f-ae48-046ee82cec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q15  What is causation? Explain difference between correlation and causation with an example. \n",
    "#     Causation :- Causation refers to a relationship where one event or variable directly influences another.\n",
    "#     In other words, causation implies that changes in one variable cause changes in another.\n",
    "#     Correlation :- It measures the strength and direction of the relationship between two variables.Correlation indicates \n",
    "#      that two variables are related, but it does not mean that one variable causes the other to change.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5122174-3d0d-45e6-92a0-a5f581999792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf79ef91-d765-40c0-ad20-fa04c53fc376",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q16   What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
    "#      An optimizer in machine learning is an algorithm or method used to adjust the parameters of a model to\n",
    "#     minimize the loss function.The goal of an optimizer is to find the optimal set of parameters that result in the \n",
    "#     best performance of the model.\n",
    "#     Types of Optimizers:\n",
    "#     1. Gradient Descent(GD): is the most common optimization algorithm. It iteratively adjusts the model's parameters in the direction of the negative\n",
    "#     gradient of the loss function.\n",
    "#     Example: In linear regression, Gradient Descent updates the weihghts to minimize the mean squared error.\n",
    "#     2. Stochastic Gradient Descent(SGD): is a varient of Gradient Descent that updates the model's parameters using a single training example at a time. This\n",
    "#     makes it faster and more suitable for large datasets.\n",
    "#     Example: In logistic regression, SGD updates the weights to minimize the binary cross-entropy loss.\n",
    "#     3. Mini-Batch Gradient Descent:is a compromise between GD and SGD. It updates the model's parameters using a small batch of training examples.\n",
    "#     Example: In neural networks, mini-Batch Gradient updates the weights to minimize the loss function using mini-batches of data.\n",
    "#     4. Adam (Adaptative Moment Estimation): is an advanced optimization algorithm that combines the benefits of both RMSprop and SGD with momentum.\n",
    "#     Example: In deep learning, Adam is widely used for training neural networks due to its efficiency \n",
    "#     and effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f92a37f-1f6d-424d-b1b1-be9c5cee1da2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6546f9dc-746b-4fdb-9f9e-0db3a12ba904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q17  What is sklearn.linear_model ?\n",
    "#    sklearn.linear_model is a module in the Scikit-learn library that provides various linear models for regression and classification tasks. These models are based on linear relationship between the input features and the target \n",
    "#    variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f672160d-8273-470d-8d4d-36fa1c26efde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5c77c71-9105-40c0-8251-18ef48e98398",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q18   What does model.fit() do? What arguments must be given?\n",
    "#     The model.fit() method in machine learning is used to train a model on agiven dataset. It adjusts the model's parameters based on the input \n",
    "#     data and the corresponding target values to minimize the error and improve the model's performance.\n",
    "#     X(input data): The features or input data used for training the model. It can be a NumPy array, pandas DataFrame, or similar data structure.\n",
    "#     Y(Target Data): The target values or labels corresponding to the input data. It can also be a NumPy array, pandas Series, or similar data structure.\n",
    "#    Only trainig data passed on model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b113026-27e5-44ca-8176-014bd4ad1e79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f81699f-fc49-4875-86a6-bcb4b83fefcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q19   What does model.predict() do? What arguments must be given?\n",
    "#      The model.predict() method in machine learning is used to make predictions on new, unseen data based on the model that has been\n",
    "#      trained. It takes the input data and returns the predicted output.\n",
    "#      X (Input Data): The features or input data for which you want to make predictions. It can be a NumPy array, pandas DataFrame, or \n",
    "#      similar data structure.\n",
    "#    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6973b70-7175-4f44-a84b-9eb598a71064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98139ded-e562-4bad-a34e-f700066331c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q20 What are continuous and categorical variables?\n",
    "#        Continuous variables: These are the variables that can take on an infinite number of values within a given\n",
    "#        range. Exampleas are height, weight, temperature etc.\n",
    "#        Categorical variables: These are variables that represent distinct categories or groups.\n",
    "#        Examples are gender, blood type and marital status etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148e6b9c-7208-48e1-b702-3631fff0d3e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b92932b-4595-4d58-afe8-2ad1ca9bc275",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q21   What is feature scaling? How does it help in Machine Learning?\n",
    "#       Feature scaling tries to bring all the features on the same scale.\n",
    "#       Many of the algorithms are distance based, that's why if high magnitude it becomes computationally expensive.\n",
    "#       Interpretation becomes easier.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592e876b-fbe6-4cb8-9421-9275301ebc19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f699a513-0d8d-45d3-b7b4-799fcba73031",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q22 How do we perform scaling in Python?\n",
    "#  To perform scaling in python, we can use the sklearn.preprocessing module from the Scikitlearn library. This module provides\n",
    "#  various scaling techniques to standardize our data.\n",
    "#  1. Standardization,\n",
    "#  2. Normalization,\n",
    "#  3. Unit vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985af04d-329c-4366-a759-cf3b5a39235a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcaa6a39-9091-4184-81f9-c920c53d1259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q23  What is sklearn.preprocessing?\n",
    "#       sklearn.preprocessing is a module in the Scikit-learn library that provides various utilities \n",
    "#       for preprocessing and transforming data before it is used to train machine learning models.\n",
    "#       With the help of this library we do Standardization, Normalization, Data encoding etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091f5a86-da5c-44a2-9b69-4060c65bf572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2e1ba2a-0454-4f72-9d6c-9276c6372218",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q24 How do we split data for model fitting (training and testing) in Python?\n",
    "#      Training Dataset: In our dataset we divide the data in 8:2 or7:3 etc means 8 data point out 10 are\n",
    "#      used for training .\n",
    "#      The dataset used to train the model.\n",
    "#      It contains input data along with the corresponding output(labels).\n",
    "#      With the help of trainig data model learns patterns and relationship from the data.\n",
    "#      Testing Dataset : 2 data out of 10 data are used at the end to check the models accuracy called \n",
    "#      as testing dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7748ac26-1dd0-428e-ba2b-f8d75b670964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d0b4a8-6632-43a8-bd4d-9d34a7fc5b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q25 Explain data encoding?\n",
    "#   Data encoding is the process of converting categorical data into a numerical \n",
    "#   format that can be used by machine learning algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
